{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activation Grids\n",
    "- This notebook does not do any visualizations, it just creates the act grids for each layer and saves them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import normalize\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "import math\n",
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "\n",
    "import lucid.modelzoo.vision_models as models\n",
    "import lucid.optvis.render as render\n",
    "from lucid.misc.io import show, load\n",
    "from lucid.misc.io.showing import _image_url\n",
    "import lucid.scratch.web.svelte as lucid_svelte\n",
    "\n",
    "import lucid.modelzoo.vision_models as models\n",
    "from lucid.misc.io import show\n",
    "import lucid.optvis.objectives as objectives\n",
    "import lucid.optvis.param as param\n",
    "import lucid.optvis.render as render\n",
    "import lucid.optvis.transform as transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "LAYERS = { 'conv1': 'Conv2D',\n",
    "           'conv1_relu':'Relu',\n",
    "           'pool1': 'MaxPool',\n",
    "           'conv2': 'Conv2D_1',\n",
    "           'conv2_relu': 'Relu_1',\n",
    "           'pool2': 'MaxPool_1',\n",
    "           'conv3': 'Conv2D_2',\n",
    "           'conv3_relu': 'Relu_2',\n",
    "           'pool3': 'MaxPool_2',\n",
    "         }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lucid.modelzoo.vision_base import Model\n",
    "\n",
    "class DLA(Model):\n",
    "    model_path = 'https://storage.googleapis.com/dla_protobuff/full_model_8_13.pb'\n",
    "    image_shape = [1, 400]\n",
    "    image_value_range = [0, 1]\n",
    "    input_name = 'x'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_input(image_file):\n",
    "    img = Image.open(image_file)\n",
    "    img = img.resize((400,267), Image.ANTIALIAS)\n",
    "    img.save(image_file)\n",
    "    \n",
    "def run(data, start, layer, hide=False):\n",
    "    flux = np.load(data)\n",
    "    flux_test = flux[start:start+400]\n",
    "    flux_test = flux_test.reshape(1, 400, 1, 1)\n",
    "    flux_graph = flux_test.reshape(400)\n",
    "    fig = plt.figure(frameon=False);\n",
    "    ax = plt.Axes(fig, [0, 0, 1, 1]);\n",
    "    ax.set_axis_off();\n",
    "    fig.add_axes(ax);\n",
    "    ax.plot(flux_graph, 'black');\n",
    "    ax.set(xlim=(0, 400));\n",
    "    file_save = 'flux_' + str(start) + '.png'\n",
    "    fig.savefig(file_save);\n",
    "    plt.close(fig)\n",
    "    resize_input(file_save)\n",
    "    acts = render_act_grid(layer, flux_test, file_save)\n",
    "    return acts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DLA()\n",
    "\n",
    "def render_act_grid(layer, test_input):\n",
    "    input_1d = test_input # Actual 1-Dimensional test input\n",
    "    \n",
    "    model_layer = LAYERS[layer]\n",
    "    \n",
    "    # Compute the activations\n",
    "    with tf.Graph().as_default(), tf.Session() as sess:\n",
    "        t_input = tf.placeholder(tf.float32, shape=[1, 400, 1, 1])\n",
    "        T = render.import_model(model, t_input, t_input)\n",
    "        acts = T(model_layer).eval(feed_dict={t_input: input_1d, 'import/keep_prob:0': .98})[0]\n",
    "    acts_flat = acts.reshape([-1] + [acts.shape[2]])\n",
    "    \n",
    "    # Render an image for each activation vector\n",
    "    param_f = lambda: param.image(400, h=1, channels=1, batch = acts.shape[0])\n",
    "    obj = objectives.Objective.sum(\n",
    "        [objectives.direction(model_layer, v, batch=n)\n",
    "         for n,v in enumerate(acts_flat)])\n",
    "    \n",
    "    thresholds = (128,)\n",
    "    vis_imgs = render.render_vis(model, obj, param_f, thresholds=thresholds, transforms=[], verbose=False)[-1]\n",
    "    vis_imgs = vis_imgs.reshape(acts.shape[0], 400)\n",
    "    \n",
    "    return vis_imgs\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the 400 length flux input\n",
    "flux = np.load(\"../data/spectra/flux0.npy\")\n",
    "flux = flux[0:400]\n",
    "flux = flux.reshape(1, 400, 1, 1)\n",
    "file_save = 'flux0_'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the 400 length flux input\n",
    "flux = np.load(\"../data/spectra/flux.npy\")\n",
    "flux = flux[700:1100]\n",
    "flux = flux.reshape(1, 400, 1, 1)\n",
    "file_save = 'flux700_'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1...\n",
      "conv1_relu...\n",
      "pool1...\n",
      "conv2...\n",
      "conv2_relu...\n",
      "pool2...\n",
      "conv3...\n",
      "conv3_relu...\n",
      "pool3...\n"
     ]
    }
   ],
   "source": [
    "for layer in LAYERS:\n",
    "    print(layer + \"...\")\n",
    "    imgs = render_act_grid(layer, flux)\n",
    "    img_flat = imgs.flatten()\n",
    "    out = file_save + layer + \".npy\"\n",
    "    np.save(out, img_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the 400 length flux input\n",
    "flux = np.load(\"../data/spectra/flux.npy\")\n",
    "flux = flux[350:750]\n",
    "flux = flux.reshape(1, 400, 1, 1)\n",
    "file_save = 'flux350_'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1...\n",
      "conv1_relu...\n",
      "pool1...\n",
      "conv2...\n",
      "conv2_relu...\n",
      "pool2...\n",
      "conv3...\n",
      "conv3_relu...\n",
      "pool3...\n"
     ]
    }
   ],
   "source": [
    "for layer in LAYERS:\n",
    "    print(layer + \"...\")\n",
    "    imgs = render_act_grid(layer, flux)\n",
    "    img_flat = imgs.flatten()\n",
    "    out = file_save + layer + \".npy\"\n",
    "    np.save(out, img_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the 400 length flux input\n",
    "flux = np.load(\"../data/spectra/flux1.npy\")\n",
    "flux = flux[1000:1400]\n",
    "flux = flux.reshape(1, 400, 1, 1)\n",
    "file_save = 'flux1_'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1...\n",
      "conv1_relu...\n",
      "WARNING:tensorflow:From /home/sam/lucid/lucid/misc/redirected_relu_grad.py:95: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/sam/lucid/lucid/misc/redirected_relu_grad.py:95: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pool1...\n",
      "conv2...\n",
      "conv2_relu...\n",
      "pool2...\n",
      "conv3...\n",
      "conv3_relu...\n",
      "pool3...\n"
     ]
    }
   ],
   "source": [
    "for layer in LAYERS:\n",
    "    print(layer + \"...\")\n",
    "    imgs = render_act_grid(layer, flux)\n",
    "    img_flat = imgs.flatten()\n",
    "    out = file_save + layer + \".npy\"\n",
    "    np.save(out, img_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
