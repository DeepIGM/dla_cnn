from astropy.io import fits
import numpy as np


class Sightline(object):

    def __init__(self, id, dlas=None, flux=None, wavelength=None,error=None, z_qso=None, ra = None, dec = None):
        """
        Args:
            id (int):  Index identifier for the sightline
            dlas (list): List of DLAs
            flux (np.ndarray):
            wavelength (np.ndarray):
                observed wavelength values
            z_qso (float):
                Quasar redshift
        """
        self.flux = flux
        self.wavelength = wavelength
        self.id = id
        self.dlas = dlas
        self.z_qso = z_qso
        self.ra = ra
        self.dec = dec
        self.error = error    # error = 1./ np.sqrt(ivar)

        # Attributes
        self.prediction = None
        self.classification = None
        self.offsets = None
        self.column_density = None


    # Returns the data in the legacy data1, qso_z format for code that hasn't been updated to the new format yet
    def get_legacy_data1_format(self):
        raw_data = {}
        raw_data['flux'] = self.flux
        raw_data['loglam'] = self.loglam
        raw_data['plate'] = self.id.plate if hasattr(self.id, 'plate') else 0
        raw_data['mjd'] = self.id.mjd if hasattr(self.id, 'mjd') else 0
        raw_data['fiber'] = self.id.fiber if hasattr(self.id, 'fiber') else 0
        raw_data['ra'] = self.id.ra if hasattr(self.id, 'ra') else 0
        raw_data['dec'] = self.id.dec if hasattr(self.id, 'dec') else 0
        return raw_data, self.z_qso


    # Clears all fields of the DLA
    def clear(self):
        self.flux = None
        self.loglam = None
        self.id = None
        self.dlas = None
        self.z_qso = None
        self.prediction = None
        self.data_markers = []


    def is_lyb(self, peakix):
        """
        Returns true if the given peakix (from peaks_ixs) is the ly-b of another DLA in the set peaks_ixs in prediction
        :param peakix:
        :return: boolean
        """
        assert self.prediction is not None and peakix in self.prediction.peaks_ixs

        lambda_higher = (10**self.loglam[peakix]) / (1025.722/1215.67)

        # An array of how close each peak is to beign the ly-b of peakix in spectrum reference frame
        peak_difference_spectrum = np.abs(10**self.loglam[self.prediction.peaks_ixs] - lambda_higher)
        nearest_peak_ix = np.argmin(peak_difference_spectrum)

        # get the column density of the identfied nearest peak
        _, potential_lya_nhi, _, _ = \
            self.prediction.get_coldensity_for_peak(self.prediction.peaks_ixs[nearest_peak_ix])
        _, potential_lyb_nhi, _, _ = \
            self.prediction.get_coldensity_for_peak(peakix)

        # Validations: check that the nearest peak is close enough to match
        #              sanity check that the LyB is at least 0.3 less than the DLA
        is_nearest_peak_within_range = peak_difference_spectrum[nearest_peak_ix] <= 15
        is_nearest_peak_larger_coldensity = potential_lyb_nhi < potential_lya_nhi - 0.3

        return is_nearest_peak_within_range and is_nearest_peak_larger_coldensity


    def get_lyb_index(self, peakix):
        """
        Returns the index location of the Ly-B absorption for a given peak index value
        :param peakix:
        :return: index location of Ly-B
        """
        spectrum_higher = 10**self.loglam[peakix]
        spectrum_lambda_lower = spectrum_higher * (1025.722 / 1215.67)
        log_lambda_lower = np.log10(spectrum_lambda_lower)
        ix_lambda_lower = (np.abs(self.loglam - log_lambda_lower)).argmin()
        return ix_lambda_lower

    def process(self, model_path):
        """  The following should follow the algorithm in process_catalog
        :param model_path:
        :return:
        """
        import json
        from dla_cnn.data_loader import scan_flux_sample
        from dla_cnn.localize_model import predictions_ann as predictions_ann_c2
        from dla_cnn.data_loader import compute_peaks, get_lam_data
        #from dla_cnn.data_loader import add_abs_to_sightline
        from dla_cnn.absorption import add_abs_to_sightline
        from dla_cnn.data_model.Prediction import Prediction
        # Fluxes
        fluxes = scan_flux_sample(self.flux, self.loglam, self.z_qso, -1, stride=1)[0]
        # Model
        with open(model_path+"_hyperparams.json",'r') as f:
            hyperparameters = json.load(f)
        loc_pred, loc_conf, offsets, density_data_flat = predictions_ann_c2(hyperparameters, fluxes, model_path)
        self.prediction = Prediction(loc_pred=loc_pred, loc_conf=loc_conf, offsets=offsets, density_data=density_data_flat)
        # Peaks
        _ = compute_peaks(self)
        # Absorbers?
        add_abs_to_sightline(self)


class DesiMock:
    """
    a class to load all spectrums from a Desi fits file.
    :attribute wavelength array-like, save the wavelength of all spectrum (all spectrum have same wavelength array)
    :attribute data, dict, using each spectra's id as its key and a dict of all data we need of this spectra as its value
      its format like spectra_id: {'FLUX':flux, 'ERROR':error, 'z_qso':z_qso, 'RA':ra, 'DEC':dec, 'DLAS':dlas'information}
      I think this format may be more readable and practical than simply take the data of each spectra apart.
    """

    def _init_(self, wavelength = None, data = {}):
        self.wavelength = wavelength
        self.data = data


    def read_fits_file(self, spec_path, truth_path, zbest_path):
        """
        read Desi Mock spectrum from a fits file, load all spectrum as a DesiMock object
        :param spec_path: spectrum file path
        :param truth_path: truth file path
        :param zbest_path: zbest file path
        :return: self.wavelength,self.data(contained all information we need)
        """
        spec = fits.open(spec_path)
        truth = fits.open(truth_path)
        zbest = fits.open(zbest_path)

        self.wavelength = np.hstack((spec[2].data.copy(), spec[7].data.copy(), spec[12].data.copy()))

        dlas_data = truth[3].data[truth[3].data.copy()['NHI']>19.3]
        spec_dlas = {}
        for item in dlas_data:
            if item[2] not in spec_dlas:
                spec_dlas[item[2]] = [('00'+str(item[3]-item[2]*1000),item[1],item[0])] # (dla_id, dla)
            else:
                spec_dlas[item[2]].append(('00'+str(item[3]-item[2]*1000),item[1],item[0]))

        test = np.array([True if item in dlas_data['TARGETID'] else False for item in spec[1].data['TARGETID'].copy()])
        for item in spec[1].data['TARGETID'].copy()[~test]:
            spec_dlas[item] = []

        spec_id = spec[1].data['TARGETID'].copy()
        flux1 = spec[3].data.copy()
        flux2 = spec[8].data.copy()
        flux3 = spec[13].data.copy()
        flux = np.hstack((flux1,flux2,flux3))
        ivar1 = spec[4].data.copy()
        ivar2 = spec[9].data.copy()
        ivar3 = spec[14].data.copy()
        error = 1./np.sqrt(np.hstack((ivar1,ivar2,ivar3)))
        z_qso = zbest[1].data['Z'].copy()
        ra = spec[1].data['TARGET_RA'].copy()
        dec = spec[1].data['TARGET_DEC'].copy()

        self.data = {spec_id[i]:{'FLUX':flux[i],'ERROR': error[i], 'z_qso':z_qso[i] , 'RA': ra[i], 'DEC':dec[i], 'DLAS':spec_dlas[spec_id[i]]} for i in range(len(spec_id))}

        return self.wavelength,self.data

    def read_sightline(self,id):
        """
        using id(int) as index to retrive each spectra in DesiMock's dataset, return  a Sightline object.
        :param id: spectra's id , a unique number for each spectra
        :return sightline:
        """
        sightline = Sightline(id)
        sightline.flux = self.data[id]['FLUX']
        sightline.error = self.data[id]['ERROR']
        sightline.z_qso = self.data[id]['z_qso']
        sightline.ra = self.data[id]['RA']
        sightline.dec = self.data[id]['DEC']
        sightline.dlas = self.data[id]['DLAS']
        sightline.wavelength = self.wavelength
        return sightline

